{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00eddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60cb0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\python-projects\\F1-pipeline\n",
      "Data path: c:\\python-projects\\F1-pipeline\\data\\raw\n",
      "Bronze folder created: c:\\python-projects\\F1-pipeline\\data\\bronze\n"
     ]
    }
   ],
   "source": [
    "project_root = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "\n",
    "data_path = project_root / \"data\" / \"raw\"\n",
    "bronze_path = project_root / \"data\" / \"bronze\"\n",
    "\n",
    "bronze_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Data path: {data_path}\")\n",
    "print(f\"Bronze folder created: {bronze_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f539f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSV files: 14\n",
      "\n",
      "  - circuits.csv\n",
      "  - constructors.csv\n",
      "  - constructor_results.csv\n",
      "  - constructor_standings.csv\n",
      "  - drivers.csv\n",
      "  - driver_standings.csv\n",
      "  - lap_times.csv\n",
      "  - pit_stops.csv\n",
      "  - qualifying.csv\n",
      "  - races.csv\n",
      "  - results.csv\n",
      "  - seasons.csv\n",
      "  - sprint_results.csv\n",
      "  - status.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = list(data_path.glob(\"*.csv\"))\n",
    "print(f\"Number of CSV files: {len(csv_files)}\\n\")\n",
    "for file in csv_files:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b9a5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PANDAS vs POLARS\n",
      "==================================================\n",
      "\n",
      " Pandas: 0.0410 seconds\n",
      "  Shape: (77, 9)\n",
      " Memory: 0.03 MB\n",
      "\n",
      " Polars: 0.0508 seconds\n",
      "  Shape: (77, 9)\n",
      " Memory: 0.01 MB\n",
      "\n",
      "Polars was 0.81x faster!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PANDAS vs POLARS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "start = time.time()\n",
    "df_pandas = pd.read_csv(data_path / \"circuits.csv\")\n",
    "pandas_time = time.time() - start\n",
    "print(f\"\\n Pandas: {pandas_time:.4f} seconds\")\n",
    "print(f\"  Shape: {df_pandas.shape}\")\n",
    "print(f\" Memory: {df_pandas.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "start = time.time()\n",
    "df_polars = pl.read_csv(data_path / \"circuits.csv\")\n",
    "polars_time = time.time() - start\n",
    "print(f\"\\n Polars: {polars_time:.4f} seconds\")\n",
    "print(f\"  Shape: {df_polars.shape}\")\n",
    "print(f\" Memory: {df_polars.estimated_size('mb'):.2f} MB\")\n",
    "\n",
    "print(f\"\\nPolars was {pandas_time / polars_time:.2f}x faster!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4520048f",
   "metadata": {},
   "source": [
    "### 1. Slower first execution:\n",
    "\n",
    "In this comparison of reading speed when running for the first time, Polars' speed may not be as expected.\n",
    "\n",
    "This is completely normal. The first time Python is “warming up” (JIT compilation, OS disk cache, etc.).\n",
    "That's why serious benchmarks always run multiple times and discard the first few executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c59d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATASET STRUCTURE: circuits\n",
      "==================================================\n",
      "\n",
      "Schema (data types):\n",
      "Schema([('circuitId', Int64), ('circuitRef', String), ('name', String), ('location', String), ('country', String), ('lat', Float64), ('lng', Float64), ('alt', Int64), ('url', String)])\n",
      "\n",
      "First 5 rows:\n",
      "shape: (5, 9)\n",
      "┌───────────┬─────────────┬─────────────┬─────────────┬───┬──────────┬─────────┬─────┬─────────────┐\n",
      "│ circuitId ┆ circuitRef  ┆ name        ┆ location    ┆ … ┆ lat      ┆ lng     ┆ alt ┆ url         │\n",
      "│ ---       ┆ ---         ┆ ---         ┆ ---         ┆   ┆ ---      ┆ ---     ┆ --- ┆ ---         │\n",
      "│ i64       ┆ str         ┆ str         ┆ str         ┆   ┆ f64      ┆ f64     ┆ i64 ┆ str         │\n",
      "╞═══════════╪═════════════╪═════════════╪═════════════╪═══╪══════════╪═════════╪═════╪═════════════╡\n",
      "│ 1         ┆ albert_park ┆ Albert Park ┆ Melbourne   ┆ … ┆ -37.8497 ┆ 144.968 ┆ 10  ┆ http://en.w │\n",
      "│           ┆             ┆ Grand Prix  ┆             ┆   ┆          ┆         ┆     ┆ ikipedia.or │\n",
      "│           ┆             ┆ Circuit     ┆             ┆   ┆          ┆         ┆     ┆ g/wiki/M…   │\n",
      "│ 2         ┆ sepang      ┆ Sepang Inte ┆ Kuala       ┆ … ┆ 2.76083  ┆ 101.738 ┆ 18  ┆ http://en.w │\n",
      "│           ┆             ┆ rnational   ┆ Lumpur      ┆   ┆          ┆         ┆     ┆ ikipedia.or │\n",
      "│           ┆             ┆ Circuit     ┆             ┆   ┆          ┆         ┆     ┆ g/wiki/S…   │\n",
      "│ 3         ┆ bahrain     ┆ Bahrain Int ┆ Sakhir      ┆ … ┆ 26.0325  ┆ 50.5106 ┆ 7   ┆ http://en.w │\n",
      "│           ┆             ┆ ernational  ┆             ┆   ┆          ┆         ┆     ┆ ikipedia.or │\n",
      "│           ┆             ┆ Circuit     ┆             ┆   ┆          ┆         ┆     ┆ g/wiki/B…   │\n",
      "│ 4         ┆ catalunya   ┆ Circuit de  ┆ Montmeló    ┆ … ┆ 41.57    ┆ 2.26111 ┆ 109 ┆ http://en.w │\n",
      "│           ┆             ┆ Barcelona-C ┆             ┆   ┆          ┆         ┆     ┆ ikipedia.or │\n",
      "│           ┆             ┆ atalunya    ┆             ┆   ┆          ┆         ┆     ┆ g/wiki/C…   │\n",
      "│ 5         ┆ istanbul    ┆ Istanbul    ┆ Istanbul    ┆ … ┆ 40.9517  ┆ 29.405  ┆ 130 ┆ http://en.w │\n",
      "│           ┆             ┆ Park        ┆             ┆   ┆          ┆         ┆     ┆ ikipedia.or │\n",
      "│           ┆             ┆             ┆             ┆   ┆          ┆         ┆     ┆ g/wiki/I…   │\n",
      "└───────────┴─────────────┴─────────────┴─────────────┴───┴──────────┴─────────┴─────┴─────────────┘\n",
      "\n",
      "Descriptive statistics:\n",
      "shape: (9, 10)\n",
      "┌────────────┬───────────┬────────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
      "│ statistic  ┆ circuitId ┆ circuitRef ┆ name   ┆ … ┆ lat       ┆ lng       ┆ alt       ┆ url       │\n",
      "│ ---        ┆ ---       ┆ ---        ┆ ---    ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
      "│ str        ┆ f64       ┆ str        ┆ str    ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str       │\n",
      "╞════════════╪═══════════╪════════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ count      ┆ 77.0      ┆ 77         ┆ 77     ┆ … ┆ 77.0      ┆ 77.0      ┆ 77.0      ┆ 77        │\n",
      "│ null_count ┆ 0.0       ┆ 0          ┆ 0      ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 0         │\n",
      "│ mean       ┆ 39.883117 ┆ null       ┆ null   ┆ … ┆ 33.442925 ┆ 1.076683  ┆ 247.01298 ┆ null      │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆ 7         ┆           │\n",
      "│ std        ┆ 23.001701 ┆ null       ┆ null   ┆ … ┆ 22.808866 ┆ 65.516951 ┆ 362.73846 ┆ null      │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆ 9         ┆           │\n",
      "│ min        ┆ 1.0       ┆ adelaide   ┆ AVUS   ┆ … ┆ -37.8497  ┆ -118.189  ┆ -7.0      ┆ http://en │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ .wikipedi │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ a.org/wik │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ i/A…      │\n",
      "│ 25%        ┆ 20.0      ┆ null       ┆ null   ┆ … ┆ 32.7774   ┆ -9.39417  ┆ 18.0      ┆ null      │\n",
      "│ 50%        ┆ 40.0      ┆ null       ┆ null   ┆ … ┆ 40.9517   ┆ 3.93083   ┆ 129.0     ┆ null      │\n",
      "│ 75%        ┆ 59.0      ┆ null       ┆ null   ┆ … ┆ 46.9589   ┆ 19.2486   ┆ 332.0     ┆ null      │\n",
      "│ max        ┆ 80.0      ┆ zolder     ┆ Zolder ┆ … ┆ 57.2653   ┆ 144.968   ┆ 2227.0    ┆ https://e │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ n.wikiped │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ ia.org/wi │\n",
      "│            ┆           ┆            ┆        ┆   ┆           ┆           ┆           ┆ ki/…      │\n",
      "└────────────┴───────────┴────────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DATASET STRUCTURE: circuits\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nSchema (data types):\")\n",
    "print(df_polars.schema)\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df_polars.head())\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df_polars.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c20c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 9)\n",
      "┌───────────┬────────────┬──────┬──────────┬───┬─────┬─────┬─────┬─────┐\n",
      "│ circuitId ┆ circuitRef ┆ name ┆ location ┆ … ┆ lat ┆ lng ┆ alt ┆ url │\n",
      "│ ---       ┆ ---        ┆ ---  ┆ ---      ┆   ┆ --- ┆ --- ┆ --- ┆ --- │\n",
      "│ u32       ┆ u32        ┆ u32  ┆ u32      ┆   ┆ u32 ┆ u32 ┆ u32 ┆ u32 │\n",
      "╞═══════════╪════════════╪══════╪══════════╪═══╪═════╪═════╪═════╪═════╡\n",
      "│ 0         ┆ 0          ┆ 0    ┆ 0        ┆ … ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
      "└───────────┴────────────┴──────┴──────────┴───┴─────┴─────┴─────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "null_counts = df_polars.null_count()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0ff9d9",
   "metadata": {},
   "source": [
    "## Save as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9da18b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original CSV: 9.87 KB\n",
      "Parquet: 10.16 KB\n",
      "File size reduction: -2.9%\n"
     ]
    }
   ],
   "source": [
    "parquet_file = bronze_path / \"circuits.parquet\"\n",
    "df_polars.write_parquet(parquet_file, compression=\"snappy\")\n",
    "\n",
    "# Compare sizes\n",
    "csv_size = (data_path / \"circuits.csv\").stat().st_size / 1024\n",
    "parquet_size = parquet_file.stat().st_size / 1024\n",
    "\n",
    "print(f\"\\nOriginal CSV: {csv_size:.2f} KB\")\n",
    "print(f\"Parquet: {parquet_size:.2f} KB\")\n",
    "print(f\"File size reduction: {((csv_size - parquet_size) / csv_size * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc059ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet read time: 0.0631 seconds\n",
      "Read Parquet was 0.80x faster than CSV!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_test = pl.read_parquet(parquet_file)\n",
    "parquet_read_time = time.time() - start\n",
    "\n",
    "print(f\"Parquet read time: {parquet_read_time:.4f} seconds\")\n",
    "print(f\"Read Parquet was {polars_time/parquet_read_time:.2f}x faster than CSV!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e493cf6",
   "metadata": {},
   "source": [
    "The circuits dataset is **TOO SMALL** (~9 rows, a few KB). The benefits of Parquet become apparent with larger datasets:\n",
    "\n",
    "- Parquet has overhead: indexes, metadata, compression.\n",
    "- For small files, that overhead > the benefit.\n",
    "- It's like using a truck to move a small box.\n",
    "\n",
    "The magic of Parquet is seen in **large files**, as we will see later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6333812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (26759, 18)\n",
      "Columns: ['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position', 'positionText', 'positionOrder', 'points', 'laps', 'time', 'milliseconds', 'fastestLap', 'rank', 'fastestLapTime', 'fastestLapSpeed', 'statusId']\n",
      "Sample:\n",
      "shape: (5, 18)\n",
      "┌──────────┬────────┬──────────┬───────────────┬───┬──────┬──────────────┬──────────────┬──────────┐\n",
      "│ resultId ┆ raceId ┆ driverId ┆ constructorId ┆ … ┆ rank ┆ fastestLapTi ┆ fastestLapSp ┆ statusId │\n",
      "│ ---      ┆ ---    ┆ ---      ┆ ---           ┆   ┆ ---  ┆ me           ┆ eed          ┆ ---      │\n",
      "│ i64      ┆ i64    ┆ i64      ┆ i64           ┆   ┆ str  ┆ ---          ┆ ---          ┆ i64      │\n",
      "│          ┆        ┆          ┆               ┆   ┆      ┆ str          ┆ str          ┆          │\n",
      "╞══════════╪════════╪══════════╪═══════════════╪═══╪══════╪══════════════╪══════════════╪══════════╡\n",
      "│ 1        ┆ 18     ┆ 1        ┆ 1             ┆ … ┆ 2    ┆ 1:27.452     ┆ 218.300      ┆ 1        │\n",
      "│ 2        ┆ 18     ┆ 2        ┆ 2             ┆ … ┆ 3    ┆ 1:27.739     ┆ 217.586      ┆ 1        │\n",
      "│ 3        ┆ 18     ┆ 3        ┆ 3             ┆ … ┆ 5    ┆ 1:28.090     ┆ 216.719      ┆ 1        │\n",
      "│ 4        ┆ 18     ┆ 4        ┆ 4             ┆ … ┆ 7    ┆ 1:28.603     ┆ 215.464      ┆ 1        │\n",
      "│ 5        ┆ 18     ┆ 5        ┆ 1             ┆ … ┆ 1    ┆ 1:27.418     ┆ 218.385      ┆ 1        │\n",
      "└──────────┴────────┴──────────┴───────────────┴───┴──────┴──────────────┴──────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "df_results = pl.read_csv(data_path / \"results.csv\", schema_overrides={\"number\": pl.Utf8, \"points\": pl.Float64})\n",
    "print(f\"Shape: {df_results.shape}\")\n",
    "print(f\"Columns: {df_results.columns}\")\n",
    "print(f\"Sample:\")\n",
    "print(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cb7a2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total races registered: 1125\n",
      "Total results: 26759\n",
      "Min year: 1950\n",
      "Max year: 2024\n",
      "\n",
      "Races per year (last 5 years):\n",
      "shape: (5, 2)\n",
      "┌──────┬───────────┐\n",
      "│ year ┆ num_races │\n",
      "│ ---  ┆ ---       │\n",
      "│ i64  ┆ u32       │\n",
      "╞══════╪═══════════╡\n",
      "│ 2024 ┆ 24        │\n",
      "│ 2023 ┆ 22        │\n",
      "│ 2022 ┆ 22        │\n",
      "│ 2021 ┆ 22        │\n",
      "│ 2020 ┆ 17        │\n",
      "└──────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "df_races = pl.read_csv(data_path / \"races.csv\")\n",
    "\n",
    "print(f\"Total races registered: {df_races.shape[0]}\")\n",
    "print(f\"Total results: {df_results.shape[0]}\")\n",
    "print(f\"Min year: {df_races['year'].min()}\")\n",
    "print(f\"Max year: {df_races['year'].max()}\")\n",
    "\n",
    "print(f\"\\nRaces per year (last 5 years):\")\n",
    "races_by_year = (\n",
    "    df_races\n",
    "    .group_by(\"year\")\n",
    "    .agg(pl.len().alias(\"num_races\"))\n",
    "    .sort(\"year\", descending=True)\n",
    "    .head(5)\n",
    ")\n",
    "print(races_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9f19534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (589081, 6)\n",
      "\n",
      "CSV read time: 0.0492s\n",
      "Parquet read time: 0.0240s\n",
      "Speedup: 2.05x faster\n",
      "\n",
      "CSV size: 16.81 MB\n",
      "Parquet size: 3.92 MB\n",
      "Size reduction: 76.7%\n"
     ]
    }
   ],
   "source": [
    "# CSV\n",
    "start = time.time()\n",
    "df_laps_csv = pl.read_csv(data_path / \"lap_times.csv\")\n",
    "csv_time = time.time() - start\n",
    "\n",
    "# Save as Parquet\n",
    "parquet_laps = bronze_path / \"lap_times.parquet\"\n",
    "df_laps_csv.write_parquet(parquet_laps, compression=\"snappy\")\n",
    "\n",
    "# Read Parquet\n",
    "start = time.time()\n",
    "df_laps_parquet = pl.read_parquet(parquet_laps)\n",
    "parquet_time = time.time() - start\n",
    "\n",
    "# Compare\n",
    "csv_size = (data_path / \"lap_times.csv\").stat().st_size / 1024**2\n",
    "parquet_size = parquet_laps.stat().st_size / 1024**2\n",
    "\n",
    "print(f\"Dataset shape: {df_laps_csv.shape}\")\n",
    "print(f\"\\nCSV read time: {csv_time:.4f}s\")\n",
    "print(f\"Parquet read time: {parquet_time:.4f}s\")\n",
    "print(f\"Speedup: {csv_time/parquet_time:.2f}x faster\")\n",
    "\n",
    "print(f\"\\nCSV size: {csv_size:.2f} MB\")\n",
    "print(f\"Parquet size: {parquet_size:.2f} MB\")\n",
    "print(f\"Size reduction: {((csv_size - parquet_size) / csv_size * 100):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab6d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV (read all, then select): 0.0129s\n",
      "Parquet (read only 2 cols): 0.0098s\n",
      "Parquet is 1.32x faster!\n",
      "\n",
      "Result shape: (589081, 2)\n"
     ]
    }
   ],
   "source": [
    "# CSV\n",
    "start = time.time()\n",
    "#df_csv_selective = pl.read_csv(data_path / \"lap_times.csv\").select([\"raceId\", \"milliseconds\"])\n",
    "df_csv_selective = pl.read_csv(data_path / \"lap_times.csv\", columns=[\"raceId\", \"milliseconds\"])\n",
    "csv_selective_time = time.time() - start\n",
    "\n",
    "# Parquet\n",
    "start = time.time()\n",
    "df_parquet_selective = pl.read_parquet(parquet_laps, columns=[\"raceId\", \"milliseconds\"])\n",
    "parquet_selective_time = time.time() - start\n",
    "\n",
    "print(f\"CSV (read all, then select): {csv_selective_time:.4f}s\")\n",
    "print(f\"Parquet (read only 2 cols): {parquet_selective_time:.4f}s\")\n",
    "print(f\"Parquet is {csv_selective_time/parquet_selective_time:.2f}x faster!\")\n",
    "\n",
    "print(f\"\\nResult shape: {df_parquet_selective.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
